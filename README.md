# Memory_Bot

Long-Term Personal AI with Persistent Memory using Neo4j + LangChain + Gemini
MemoryAI is a personal AI system that remembers conversations across sessions, stores long-term memories in a graph database (Neo4j), and recalls relevant context intelligently using LangChain + Gemini.

## Features

- **Long-term memory** across chats and restarts
- **Graph-based memory storage** using Neo4j
- **Context-aware memory recall**
- **Memory confidence & decay support** (extensible)
- **Gemini LLM integration** via LangChain
- **FastAPI backend** 
- **Streamlit frontend** for intuitive UI
- **Fully Dockerized** (Backend + Frontend + Neo4j)
- **Response is sent back to user.**

## Project Structure
```
MemoryAI/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ init.py
â”‚ â”œâ”€â”€ chain.py # LangChain execution logic
â”‚ â”œâ”€â”€ config.py # Environment config loader
â”‚ â”œâ”€â”€ gemini.py # Gemini LLM + embeddings
â”‚ â”œâ”€â”€ main.py # FastAPI app entry
â”‚ â”œâ”€â”€ memory_store.py # Neo4j memory layer
â”‚ â”œâ”€â”€ Dockerfile # Backend Dockerfile
â”‚ â””â”€â”€ test.py # Backend tests
â”‚
â”œâ”€â”€ frontend/
â”‚ â”œâ”€â”€ app.py # Streamlit UI
â”‚ â””â”€â”€ Dockerfile # Frontend Dockerfile
â”‚
â”œâ”€â”€ .env # Environment variables
â”œâ”€â”€ docker-compose.yml # Full system orchestration
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ LICENSE # MIT License
â””â”€â”€ README.md # This file
```


## ðŸ”§ Tech Stack

- **LLM**: Google Gemini (via LangChain)
- **Memory DB**: Neo4j (Graph Database)
- **Backend**: FastAPI
- **Frontend**: Streamlit
- **Orchestration**: Docker & Docker Compose

## Environment Variables

Create a `.env` file in the root directory:

```
GEMINI_API_KEY=your_gemini_api_key
NEO4J_URI=bolt://neo4j:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
```
## Docker Setup
Build & Run Everything
```
docker compose up --build
```

**This starts:**
- Neo4j â†’ http://localhost:7474
- Backend â†’ http://localhost:8000
- Frontend â†’ http://localhost:8501

## Data Flow
1. **User Input **â†’ User sends message via Streamlit frontend with their user_id
2.** API Receipt** â†’ FastAPI backend receives POST /chat request with message and user ID
3. **Memory Check **â†’ System checks if message contains memory recall triggers (keywords, questions, or contextual cues)
4.** Recall Path** â†’ If recalling memories:
    - Queries Neo4j for relevant user memories.
    - Retrieves top N contextually relevant memories.
    - Passes memories + current message to LLM.
5. **Storage Path** â†’ If not recalling:
    - Routes message through memory importance filter.
    - Extracts important personal facts using LLM.
    - Stores significant facts in Neo4j as structured memory nodes.
6. **Response Generation** â†’ LLM generates response using:
    - Current conversation context.
    - Retrieved memories (if any).
    - System instructions for memory management.
7. **Response Delivery** â†’ Generated response sent back through API â†’ displayed in frontend.
8. **Memory Update** â†’ Memory access counters and timestamps updated in Neo4j.
